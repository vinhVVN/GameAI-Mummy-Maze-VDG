import time
import random
from collections import deque

class NoInformationProblem:
    def __init__(self, maze, initial_positions_count=2, goal_positions_count=10):  # TÄƒng lÃªn 10
        self.maze = maze
        self.goal_pos = maze.calculate_stair()
        # GIáº¢M belief state ban Ä‘áº§u chá»‰ cÃ²n 2 vá»‹ trÃ­
        self.initial_belief_state = self.get_limited_initial_positions(initial_positions_count)
        # TÄ‚NG goal belief state lÃªn 10 vá»‹ trÃ­ Ä‘Ã­ch
        self.goal_belief_state = self.generate_goal_belief(goal_positions_count)

    def get_limited_initial_positions(self, count=2):
        """Tráº£ vá» sá»‘ lÆ°á»£ng giá»›i háº¡n vá»‹ trÃ­ cÃ³ thá»ƒ Ä‘i Ä‘Æ°á»£c trong maze"""
        all_positions = []
        for y in range(len(self.maze.map_data)):
            for x in range(len(self.maze.map_data[0])):
                if self.maze.is_passable(x, y):
                    all_positions.append((x, y))
        # Láº¥y ngáº«u nhiÃªn 'count' vá»‹ trÃ­ tá»« táº¥t cáº£ vá»‹ trÃ­ cÃ³ thá»ƒ
        if len(all_positions) <= count:
            return set(all_positions)
        else:
            return set(random.sample(all_positions, count))

    def generate_goal_belief(self, count=10):  # TÄƒng lÃªn 10
        """Táº¡o táº­p goal belief vá»›i nhiá»u vá»‹ trÃ­ xung quanh goal thá»±c"""
        goal_belief = set()
        goal_x, goal_y = self.goal_pos
        
        # ThÃªm goal chÃ­nh
        goal_belief.add(self.goal_pos)
        
        # ThÃªm cÃ¡c vá»‹ trÃ­ xung quanh goal (lÃ¢n cáº­n 1)
        directions = [(0, -1), (0, 1), (-1, 0), (1, 0)]
        for dx, dy in directions:
            new_x, new_y = goal_x + dx, goal_y + dy
            if (0 <= new_x < len(self.maze.map_data[0]) and 
                0 <= new_y < len(self.maze.map_data) and 
                self.maze.is_passable(new_x, new_y)):
                goal_belief.add((new_x, new_y))
        
        # ThÃªm cÃ¡c vá»‹ trÃ­ xung quanh xa hÆ¡n (lÃ¢n cáº­n 2)
        extended_directions = [(0, -2), (0, 2), (-2, 0), (2, 0), (-1, -1), (-1, 1), (1, -1), (1, 1)]
        for dx, dy in extended_directions:
            new_x, new_y = goal_x + dx, goal_y + dy
            if (0 <= new_x < len(self.maze.map_data[0]) and 
                0 <= new_y < len(self.maze.map_data) and 
                self.maze.is_passable(new_x, new_y)):
                goal_belief.add((new_x, new_y))
        
        # ThÃªm cÃ¡c vá»‹ trÃ­ ngáº«u nhiÃªn khÃ¡c náº¿u cáº§n
        all_positions = []
        for y in range(len(self.maze.map_data)):
            for x in range(len(self.maze.map_data[0])):
                if self.maze.is_passable(x, y) and (x, y) not in goal_belief:
                    all_positions.append((x, y))
        
        while len(goal_belief) < count and all_positions:
            pos = random.choice(all_positions)
            goal_belief.add(pos)
            all_positions.remove(pos)
        
        return frozenset(goal_belief)

    def get_init_state(self):
        return frozenset(self.initial_belief_state)

    def is_goal_state(self, belief_state):
        """Äáº¡t goal khi belief state lÃ  táº­p con cá»§a goal belief state"""
        return belief_state.issubset(self.goal_belief_state)

    def get_successors(self, belief_state):
        """TÃ­nh cÃ¡c belief state káº¿ tiáº¿p"""
        possible_actions = ["UP", "DOWN", "LEFT", "RIGHT"]
        successors = []
        for action in possible_actions:
            new_belief_state = set()
            dx, dy = 0, 0
            if action == "UP":
                dy = -1
            elif action == "DOWN":
                dy = 1
            elif action == "LEFT":
                dx = -1
            elif action == "RIGHT":
                dx = 1
            for x, y in belief_state:
                # Thá»­ di chuyá»ƒn tá»« vá»‹ trÃ­ (x,y)
                new_x, new_y = x + dx, y + dy
                if self.maze.is_passable(new_x, new_y):
                    new_belief_state.add((new_x, new_y))
                else:
                    new_belief_state.add((x, y))
            frozen_state = frozenset(new_belief_state)
            successors.append((frozen_state, action, 1))
        return successors

# PhiÃªn báº£n BFS vá»›i giá»›i háº¡n cháº·t hÆ¡n
def BFS_NoInformation_Limited(problem, max_path_length=50, logger=None):
    """BFS vá»›i giá»›i háº¡n Ä‘Æ°á»ng Ä‘i ngáº¯n hÆ¡n"""
    start_time = time.perf_counter()
    start_node = problem.get_init_state()
    
    if logger:
        logger.log(f"Báº¯t Ä‘áº§u BFS Limited vá»›i {len(start_node)} vá»‹ trÃ­, max_path={max_path_length}")
        logger.log(f"Goal belief state ({len(problem.goal_belief_state)} vá»‹ trÃ­): {problem.goal_belief_state}")

    queue = deque([(start_node, [])])
    explored = set([start_node])
    iteration = 0

    while queue and iteration < 1000000:
        iteration += 1
        current_state, path_so_far = queue.popleft()

        if iteration % 1000 == 0 and logger:
            logger.log(f"BFS Limited - Iter {iteration}: Belief size={len(current_state)}, Path length={len(path_so_far)}")

        if problem.is_goal_state(current_state):
            end_time = time.perf_counter()
            if logger:
                logger.log(f"ğŸ¯ TÃ¬m tháº¥y goal sau {iteration} iterations!")
            return {
                "path": path_so_far,
                "nodes_expanded": iteration,
                "time_taken": end_time - start_time,
                "path_length": len(path_so_far)
            }

        # Giá»›i háº¡n Ä‘á»™ dÃ i Ä‘Æ°á»ng Ä‘i cháº·t hÆ¡n
        if len(path_so_far) < max_path_length:
            successors = problem.get_successors(current_state)
            for next_state, action, _ in successors:
                if next_state not in explored:
                    explored.add(next_state)
                    new_path = path_so_far + [action]
                    queue.append((next_state, new_path))

    if logger:
        logger.log(f"BFS Limited khÃ´ng tÃ¬m tháº¥y Ä‘Æ°á»ng Ä‘i sau {iteration} bÆ°á»›c")
        
    end_time = time.perf_counter()
    return {
        "path": None,
        "nodes_expanded": iteration,
        "time_taken": end_time - start_time,
        "path_length": 0
    }